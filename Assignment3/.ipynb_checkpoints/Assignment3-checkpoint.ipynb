{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS171 - Winter 2020 - Assignment 3\n",
    "### Instructor: Vagelis Papalexakis\n",
    "### TA: Yorgos Tsitsikas\n",
    "### Credit for  Assignment 3: 15/40 points of the final grade\n",
    "\n",
    "In this assignment we will implement the K-means clustering algorithm. We are going to use the same dataset as in the previous two assignments (<b>Note</b>: make sure you copy the dataset from Assignment 1 to the folder of this assignment!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import random as rand\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label']\n",
    "data = pd.read_csv('iris.data', \n",
    "                   names = data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Implementing and testing K-means clustering [100%]\n",
    "### Question 1a: Implementing K-Means clustering [50%]\n",
    "In this question you should implement a function that performs k-means clustering, using the Euclidean distance (you may use Numpy libraries for the distance computation). For calculation of the centroid you should use the 'mean' function.\n",
    "\n",
    "For uniformity, you should implement a function with the following specifications:\n",
    "```python\n",
    "def kmeans_clustering(all_vals,K,max_iter = 100, tol = pow(10,-3) ):\n",
    "```\n",
    "where 1) 'all_vals' is the $N \\times M$ matrix that contains all data points ($N$ is the number of data points and $M$ is the number of features, each row of the matrix is a data point), 2) 'K' is the number of clusters, 3) 'max_iter' is the maxium number of iterations, and 4) 'tol' is the tolerance for the change of the sum of squares of errors that determines convergence.\n",
    "\n",
    "Your function should return the following variables: 1) 'assignments': this is a $N\\times 1$ vector (where $N$ is the number of data points) where the $i$-th position of that vector contains the cluster number that the $i$-th data point is assigned to, 2) 'centroids': this is a $K\\times M$ matrix, each row of which contains the centroid for every cluster, 3) 'all_sse': this is a vector that contains all the sum of squares of errors per iteration of the algorithm, and 4) 'iters': this is the number of iterations that the algorithm ran.\n",
    "\n",
    "Here we are going to implement the simplest version of K-means, where the initial centroids are chosen entirely at random among all the data points.\n",
    "\n",
    "As we saw in class, the K-means algorithm iterates over the following steps:\n",
    "- Given a set of centroids, assign all data points to the cluster represented by its nearest centroid (according to Euclidean distance)\n",
    "- Given a set of assignments of points to clusters, compute the new centroids for every cluster, by taking the mean of all the points assigned to each cluster.\n",
    "\n",
    "Your algorithm should converge if 1) the maximum number of iterations is reached, or 2) if the SSE between two consecutive iterations does not change a lot (as in the gradient descent for linear regression we saw in Assignment 2). In order to check for the latter condition, you may use the following piece of code:\n",
    "```python\n",
    "if np.absolute(all_sse[it] - all_sse[it-1])/all_sse[it-1] <= tol\n",
    "```\n",
    "\n",
    "In order to calculate the SSE (sum of squares of error) first you need to define what an 'error' is. In k-means, error per data point refers to the Euclidean distance of that particular point from its assigned centroid. SSE sums up all those squared Euclidean distances for all data points and comes up with a number that reflects the total error of approximating every data points by its assigned centroid.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment array for last iteration:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0] \n",
      "\n",
      "centroids for last iteration:  [[5.88360655737705, 2.7409836065573767, 4.388524590163935, 1.4344262295081966], [5.006, 3.418, 1.464, 0.244], [6.853846153846154, 3.076923076923077, 5.715384615384615, 2.0538461538461537]] \n",
      "\n",
      "number of iterations for convergence:  100 \n",
      "\n",
      "all sse array:  [119.37000000000006, 201.70137226813605, 282.8717064090595, 362.83468624367254, 442.2684503889993, 521.2791601112215, 600.224225937199, 679.1692917631765, 758.114357589154, 837.0594234151315, 916.004489241109, 994.9495550670865, 1073.8946208930633, 1152.8396867190406, 1231.784752545018, 1310.7298183709952, 1389.6748841969725, 1468.6199500229498, 1547.565015848927, 1626.5100816749043, 1705.4551475008816, 1784.4002133268589, 1863.3452791528362, 1942.2903449788134, 2021.2354108047907, 2100.180476630766, 2179.1255424567407, 2258.0706082827155, 2337.0156741086903, 2415.960739934665, 2494.90580576064, 2573.8508715866146, 2652.7959374125894, 2731.741003238564, 2810.686069064539, 2889.6311348905137, 2968.5762007164885, 3047.5212665424633, 3126.466332368438, 3205.411398194413, 3284.3564640203876, 3363.3015298463624, 3442.246595672337, 3521.191661498312, 3600.1367273242868, 3679.0817931502615, 3758.0268589762363, 3836.971924802211, 3915.916990628186, 3994.8620564541607, 4073.8071222801354, 4152.752188106115, 4231.697253932094, 4310.642319758073, 4389.587385584053, 4468.532451410032, 4547.477517236011, 4626.422583061991, 4705.36764888797, 4784.312714713949, 4863.257780539929, 4942.202846365908, 5021.147912191887, 5100.092978017867, 5179.038043843846, 5257.983109669825, 5336.928175495805, 5415.873241321784, 5494.818307147763, 5573.763372973743, 5652.708438799722, 5731.653504625701, 5810.598570451681, 5889.54363627766, 5968.488702103639, 6047.433767929619, 6126.378833755598, 6205.323899581577, 6284.268965407557, 6363.214031233536, 6442.159097059515, 6521.104162885495, 6600.049228711474, 6678.994294537453, 6757.939360363433, 6836.884426189412, 6915.829492015391, 6994.774557841371, 7073.71962366735, 7152.664689493329, 7231.6097553193085, 7310.554821145288, 7389.499886971267, 7468.4449527972465, 7547.390018623226, 7626.335084449205, 7705.2801502751845, 7784.225216101164, 7863.170281927143, 7942.1153477531225]\n"
     ]
    }
   ],
   "source": [
    "def remove_labels(d):\n",
    "    \n",
    "    ##removing the last column which contains the labels\n",
    "    new_d = np.array(d)\n",
    "    new_d = new_d[:,:-1]\n",
    "    \n",
    "    return new_d\n",
    "\n",
    "\n",
    "def kmeans_clustering(all_vals,K,max_iter, tol):\n",
    "    \n",
    "    #initialize data\n",
    "    centroids = []\n",
    "    ##assignments = []\n",
    "    all_sse=[]\n",
    "    iters=0\n",
    "    error,ssqe= 0,0\n",
    "    \n",
    "    #initializng the centroids for each cluster, K x M (3 x 4) matrix with random numbers from datapoints \n",
    "    \n",
    "    rand_centroid = all_vals[np.random.randint(0, len(all_vals)-1, size=K)]\n",
    "    \n",
    "    centroids = rand_centroid\n",
    "#     print(\"random centroids for first iteration: \", centroids,\"\\n\")\n",
    "#     print(\"all val\", all_vals)\n",
    "        \n",
    "    for iters in range(max_iter):\n",
    "        \n",
    "        assignments = []\n",
    "        \n",
    "        for i in range(len(all_vals)):\n",
    "            #datapoint is closer to the first clusterpoint\n",
    "            if ((np.linalg.norm(centroids[0][0:4] - all_vals[i][0:4]) < \n",
    "                np.linalg.norm(centroids[1][0:4] - all_vals[i][0:4])) and \n",
    "               (np.linalg.norm(centroids[0][0:4] - all_vals[i][0:4]) < \n",
    "                np.linalg.norm(centroids[2][0:4] - all_vals[i][0:4]))):\n",
    "                \n",
    "                error=np.linalg.norm(centroids[0][0:4] - all_vals[i][0:4])\n",
    "                assignments.append(0)\n",
    "          \n",
    "\n",
    "            #datapoint is closer to the second clusterpoint\n",
    "            elif((np.linalg.norm(centroids[1][0:4] - all_vals[i][0:4]) < \n",
    "                np.linalg.norm(centroids[0][0:4] - all_vals[i][0:4])) and \n",
    "               (np.linalg.norm(centroids[1][0:4] - all_vals[i][0:4]) < \n",
    "                np.linalg.norm(centroids[2][0:4] - all_vals[i][0:4]))):\n",
    "                \n",
    "                error=np.linalg.norm(centroids[1][0:4] - all_vals[i][0:4])\n",
    "                assignments.append(1)\n",
    "            \n",
    "            #datapoint is closer to the third clusterpoint \n",
    "            else:\n",
    "                error=np.linalg.norm(centroids[2][0:4] - all_vals[i][0:4])\n",
    "                assignments.append(2)\n",
    "            \n",
    "            ##computing sum of sse\n",
    "            error=pow(error,2)\n",
    "            ssqe+=error\n",
    "               \n",
    "        all_sse.append(ssqe)\n",
    "        \n",
    "        ##computing new centroid\n",
    "        f1,f2,f3,f4=0,0,0,0\n",
    "        f1_arr_k1,f2_arr_k1,f3_arr_k1,f4_arr_k1=[],[],[],[]\n",
    "        f1_arr_k2,f2_arr_k2,f3_arr_k2,f4_arr_k2=[],[],[],[]\n",
    "        f1_arr_k3,f2_arr_k3,f3_arr_k3,f4_arr_k3=[],[],[],[]\n",
    "        \n",
    "        c_0_0,c_0_1,c_0_2,c_0_3=0,0,0,0\n",
    "        c_1_0,c_1_1,c_1_2,c_1_3=0,0,0,0\n",
    "        c_2_0,c_2_1,c_2_2,c_2_3=0,0,0,0\n",
    "        \n",
    "        for j in range(len(assignments)):\n",
    "            if assignments[j]==0:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k1.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k1.append(f2)\n",
    "                f3=all_vals[j][2]\n",
    "                f3_arr_k1.append(f3)\n",
    "                f4=all_vals[j][3]\n",
    "                f4_arr_k1.append(f4)\n",
    "            elif assignments[j]==1:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k2.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k2.append(f2)\n",
    "                f3=all_vals[j][2]\n",
    "                f3_arr_k2.append(f3)\n",
    "                f4=all_vals[j][3]\n",
    "                f4_arr_k2.append(f4)\n",
    "            else:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k3.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k3.append(f2)\n",
    "                f3=all_vals[j][2]\n",
    "                f3_arr_k3.append(f3)\n",
    "                f4=all_vals[j][3]\n",
    "                f4_arr_k3.append(f4)\n",
    "                \n",
    "        ##taking the mean of all the points assigned to each cluster\n",
    "        \n",
    "        c_0_0=np.mean(f1_arr_k1)\n",
    "        c_0_1=np.mean(f2_arr_k1)\n",
    "        c_0_2=np.mean(f3_arr_k1)\n",
    "        c_0_3=np.mean(f4_arr_k1)\n",
    "        \n",
    "        c_1_0=np.mean(f1_arr_k2)\n",
    "        c_1_1=np.mean(f2_arr_k2)\n",
    "        c_1_2=np.mean(f3_arr_k2)\n",
    "        c_1_3=np.mean(f4_arr_k2)\n",
    "        \n",
    "        c_2_0=np.mean(f1_arr_k3)\n",
    "        c_2_1=np.mean(f2_arr_k3)\n",
    "        c_2_2=np.mean(f3_arr_k3)\n",
    "        c_2_3=np.mean(f4_arr_k3)\n",
    "        \n",
    "        new_c=[[c_0_0,c_0_1,c_0_2,c_0_3],\n",
    "               [c_1_0,c_1_1,c_1_2,c_1_3],\n",
    "               [c_2_0,c_2_1,c_2_2,c_2_3]]\n",
    "        \n",
    "        ##print(\"new c: \", new_c)\n",
    "        centroids=new_c\n",
    "        \n",
    "        ##converge if this condition is true\n",
    "        if(iters>=1):\n",
    "            if(np.absolute(all_sse[iters] - all_sse[iters-1])/all_sse[iters-1] <= tol):\n",
    "                break                  \n",
    "\n",
    "    return assignments,iters,centroids,all_sse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_data=remove_labels(data)\n",
    "assignment,iters,centroids,all_sse=kmeans_clustering(new_data,3,100, pow(10,-3))\n",
    "print(\"assignment array for last iteration: \", assignment,\"\\n\")\n",
    "print(\"centroids for last iteration: \", centroids,\"\\n\")\n",
    "print(\"number of iterations for convergence: \", iters+1,\"\\n\")\n",
    "print(\"all sse array: \", all_sse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b: Visualizing K-means [10%]\n",
    "In this question we wll visualize the result of the K-means algorithm. For ease of visualization, we will focus on a scatterplot of two of the four features of the Iris dataset. In particular: run your K-means code with K=3 and default values for the rest of the inputs. Subsequently, make a single scatterplot that contains all data points of the dataset for features 'sepal_length' and 'petal_length' and color every data point according to its cluster assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment array for last iteration:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here: changed code to only compute for 3 clusters and 2 feautres 'sepal_length' and 'petal_length'\n",
    "def remove_labels(d):\n",
    "    \n",
    "    ##removing the last column which contains the labels\n",
    "    new_d = np.array(d)\n",
    "    new_d = new_d[:,:-1]\n",
    "    \n",
    "    return new_d\n",
    "\n",
    "\n",
    "def kmeans_clusteringv3(all_vals,K,max_iter, tol):\n",
    "    \n",
    "    #initialize data\n",
    "    centroids = []\n",
    "    ##assignments = []\n",
    "    all_sse=[]\n",
    "    iters=0\n",
    "    error,ssqe= 0,0\n",
    "    \n",
    "    #initializng the centroids for each cluster, K x M (3 x 2) matrix with random numbers from datapoints \n",
    "    \n",
    "    rand_centroid = all_vals[np.random.randint(0, len(all_vals)-1, size=K)]\n",
    "    \n",
    "    centroids = rand_centroid\n",
    "#     print(\"random centroids for first iteration: \", centroids,\"\\n\")\n",
    "\n",
    "    ##print(\"all_val\",all_vals)\n",
    "    for iters in range(max_iter):\n",
    "        \n",
    "        assignments = []\n",
    "        \n",
    "        for i in range(len(all_vals)):\n",
    "            #datapoint is closer to the first clusterpoint\n",
    "            if ((np.linalg.norm(centroids[0][0:2] - all_vals[i][0:2]) < \n",
    "                np.linalg.norm(centroids[1][0:2] - all_vals[i][0:2])) and \n",
    "               (np.linalg.norm(centroids[0][0:2] - all_vals[i][0:2]) < \n",
    "                np.linalg.norm(centroids[2][0:2] - all_vals[i][0:2]))):\n",
    "                \n",
    "                error=np.linalg.norm(centroids[0][0:2] - all_vals[i][0:2])\n",
    "                assignments.append(0)\n",
    "          \n",
    "\n",
    "            #datapoint is closer to the second clusterpoint\n",
    "            elif((np.linalg.norm(centroids[1][0:2] - all_vals[i][0:2]) < \n",
    "                np.linalg.norm(centroids[0][0:2] - all_vals[i][0:2])) and \n",
    "               (np.linalg.norm(centroids[1][0:2] - all_vals[i][0:2]) < \n",
    "                np.linalg.norm(centroids[2][0:2] - all_vals[i][0:2]))):\n",
    "                \n",
    "                error=np.linalg.norm(centroids[1][0:2] - all_vals[i][0:2])\n",
    "                assignments.append(1)\n",
    "            \n",
    "            #datapoint is closer to the third clusterpoint \n",
    "            else:\n",
    "                error=np.linalg.norm(centroids[2][0:2] - all_vals[i][0:2])\n",
    "                assignments.append(2)\n",
    "            \n",
    "            ##computing sum of sse\n",
    "            error=pow(error,2)\n",
    "            ssqe+=error\n",
    "               \n",
    "        all_sse.append(ssqe)\n",
    "        \n",
    "        ##computing new centroid\n",
    "        f1,f2,f3,f4=0,0,0,0\n",
    "        f1_arr_k1,f2_arr_k1=[],[]\n",
    "        f1_arr_k2,f2_arr_k2=[],[]\n",
    "        f1_arr_k3,f2_arr_k3=[],[]\n",
    "        \n",
    "        c_0_0,c_0_1=0,0\n",
    "        c_1_0,c_1_1,=0,0\n",
    "        c_2_0,c_2_1=0,0\n",
    "        \n",
    "        for j in range(len(assignments)):\n",
    "            if assignments[j]==0:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k1.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k1.append(f2)\n",
    "            elif assignments[j]==1:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k2.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k2.append(f2)\n",
    "            else:\n",
    "                f1=all_vals[j][0]\n",
    "                f1_arr_k3.append(f1)\n",
    "                f2=all_vals[j][1]\n",
    "                f2_arr_k3.append(f2)\n",
    "                \n",
    "        ##taking the mean of all the points assigned to each cluster\n",
    "        \n",
    "        c_0_0=np.mean(f1_arr_k1)\n",
    "        c_0_1=np.mean(f2_arr_k1)\n",
    "        \n",
    "        \n",
    "        c_1_0=np.mean(f1_arr_k2)\n",
    "        c_1_1=np.mean(f2_arr_k2)\n",
    "      \n",
    "        \n",
    "        c_2_0=np.mean(f1_arr_k3)\n",
    "        c_2_1=np.mean(f2_arr_k3)\n",
    "       \n",
    "        \n",
    "        new_c=[[c_0_0,c_0_1],\n",
    "               [c_1_0,c_1_1],\n",
    "               [c_2_0,c_2_1]]\n",
    "        \n",
    "        ##print(\"new c: \", new_c)\n",
    "        centroids=new_c\n",
    "        \n",
    "        ##conberge if this condition is true\n",
    "        if(iters>=1):\n",
    "            if(np.absolute(all_sse[iters] - all_sse[iters-1])/all_sse[iters-1] <= tol):\n",
    "                break                  \n",
    "\n",
    "    return assignments,iters,centroids,all_sse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "petal_vs_sepal = data[['sepal_width', 'petal_length']].values\n",
    "# print(petal_vs_sepal)\n",
    "##new_data=remove_labels(petal_vs_sepal)\n",
    "assignment1b,iters,centroids,all_sse=kmeans_clusteringv3(petal_vs_sepal,3,100, pow(10,-3))\n",
    "print(\"assignment array for last iteration: \", assignment1b,\"\\n\")\n",
    "# print(\"centroids for last iteration: \", centroids,\"\\n\")\n",
    "# print(\"number of iterations for convergence: \", iters+1,\"\\n\")\n",
    "# print(\"all sse array: \", all_sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first cluster k=1: red, second cluster k=2: green , third cluster k=3: blue\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1,kplot1 = plt.subplots()\n",
    "\n",
    "##_k = [x for x in range(1,4)]\n",
    "\n",
    "categories=assignment1b\n",
    "colormap=np.array(['r', 'g', 'b'])\n",
    "\n",
    "d1_cluster_list,d1_list,d2_cluster_list,d2_list=[],[],[],[]\n",
    "\n",
    "for c in range(len(assignment1b)):\n",
    "    if assignment1b[c]==0:\n",
    "        cluster='k=1'\n",
    "        d1=petal_vs_sepal[c][0]\n",
    "        d2=petal_vs_sepal[c][1]\n",
    "    elif assignment1b[c]==1:\n",
    "        cluster='k=2'\n",
    "        d1=petal_vs_sepal[c][0]\n",
    "        d2=petal_vs_sepal[c][1]\n",
    "    else:\n",
    "        cluster='k=3'\n",
    "        d1=petal_vs_sepal[c][0]\n",
    "        d2=petal_vs_sepal[c][1]\n",
    "        \n",
    "    d1_cluster_list.append(cluster)\n",
    "    d1_list.append(d1)\n",
    "    d2_cluster_list.append(cluster)\n",
    "    d2_list.append(d2)\n",
    "\n",
    "kplot1.scatter(d1_cluster_list, d1_list, c=colormap[categories])\n",
    "kplot1.scatter(d2_cluster_list, d2_list, c=colormap[categories])\n",
    "print(\"first cluster k=1: red, second cluster k=2: green , third cluster k=3: blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c: Testing K-means [40%]\n",
    "Selecting the right number of clusters $K$ is a very challenging problem, especially when we don't have some side-information or domain expertise that can help us narrow down a few reasonable values for that parameter. \n",
    "\n",
    "In the absence of any other information, a very useful exercise is to create the plot of SSE (sum of squares of errors) as a function of $K$. Ideally, for a very small $K$, the error will be high (since we are trying to approximate a whole lot of points with a very small number of centroids) and as $K$ increases, the error decreases. However, after a certain value (or a couple of values) for $K$, we will notice diminishing returns, i.e., the error will be decreasing, but not to a great degree. Typically, the value(s) for $K$ where this behavior is observed (the threshold point after which we observe diminishing returns) is usually a good guess for the number of clusters. \n",
    "\n",
    "In this question, we will have to create the SSE vs. K plot for $K = 1\\cdots10$. Furthermore, because K-means uses randomized initialization, we need to do a number of iterations per value of $K$ in order to get a good estimate of the actual SSE (which may not be caused by randomness in the initialization). For this question, you will have to run the entire K-means algorithm to completion, and repeat it 50 different times per $K$, and collect all SSEs. In the figure, you should report the mean SSE per $K$, surrounded by error-bars which will encode the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here: changed code so number of K could be changed\n",
    "def remove_labels(d):\n",
    "    \n",
    "    ##removing the last column which contains the labels\n",
    "    new_d = np.array(d)\n",
    "    new_d = new_d[:,:-1]\n",
    "    return new_d\n",
    "\n",
    "\n",
    "def kmeans_clusteringv2(all_vals,K,max_iter, tol):\n",
    "    \n",
    "    #initialize data\n",
    "    centroids = []\n",
    "    all_sse=[]\n",
    "    iters=0\n",
    "    error,ssqe= 0,0\n",
    "    \n",
    "    #initializng the centroids for each cluster, K x M (3 x 4) matrix with random numbers from datapoints \n",
    "    rand_centroid = all_vals[np.random.randint(0, len(all_vals)-1, size=K)]\n",
    "    centroids = rand_centroid\n",
    "#     print(\"centroids: \\n\", centroids)\n",
    " \n",
    "    \n",
    "    for iters in range(max_iter):\n",
    "                \n",
    "        assignments = []\n",
    "        \n",
    "        for i in range(len(all_vals)):\n",
    "            _min = math.inf\n",
    "            c=-1\n",
    "            for k in range(0,K):\n",
    "                if (_min > np.linalg.norm(centroids[k][0:4] - all_vals[i][0:4])):\n",
    "                    _min=np.linalg.norm(centroids[k][0:4] - all_vals[i][0:4])\n",
    "                    c=k\n",
    "                    error=_min\n",
    "                    \n",
    "            error=pow(error,2)\n",
    "            ssqe+=error\n",
    "            assignments.append(c)\n",
    "                    \n",
    "        all_sse.append(ssqe)\n",
    "        \n",
    "        \n",
    "        ##computing new centroid\n",
    "        f1,f2,f3,f4=0,0,0,0\n",
    "        list_k=[k for k in range(K)]\n",
    "        \n",
    "        ##declaring dynamic variable names since K changes everytime the function is called\n",
    "        for g in range(K):\n",
    "            globals()[f\"f1_arr_k{g}\"] = []\n",
    "            globals()[f\"f2_arr_k{g}\"] = []\n",
    "            globals()[f\"f3_arr_k{g}\"] = []\n",
    "            globals()[f\"f4_arr_k{g}\"] = []\n",
    "            globals()[f\"c_k{g}_0\"] = 0\n",
    "            globals()[f\"c_k{g}_1\"] = 0\n",
    "            globals()[f\"c_k{g}_2\"] = 0\n",
    "            globals()[f\"c_k{g}_3\"] = 0\n",
    "        \n",
    "        for j in range(len(assignments)):\n",
    "            \n",
    "            if assignments[j] in list_k:\n",
    "                f1=all_vals[j][0]\n",
    "                f2=all_vals[j][1]\n",
    "                f3=all_vals[j][2]\n",
    "                f4=all_vals[j][3]\n",
    "                globals()[f\"f1_arr_k{assignments[j]}\"].append(f1)\n",
    "                globals()[f\"f2_arr_k{assignments[j]}\"].append(f2)\n",
    "                globals()[f\"f3_arr_k{assignments[j]}\"].append(f3)\n",
    "                globals()[f\"f4_arr_k{assignments[j]}\"].append(f4)\n",
    "        \n",
    "        new_c=[] \n",
    "        \n",
    "        ##computing the mean of all points assigned to each cluster\n",
    "        for k in range(K):\n",
    "            \n",
    "#             print(\"#\", k)\n",
    "\n",
    "            globals()[f\"c_k{k}_0\"]=np.mean(globals()[f\"f1_arr_k{k}\"])\n",
    "            globals()[f\"c_k{k}_1\"]=np.mean(globals()[f\"f2_arr_k{k}\"])\n",
    "            globals()[f\"c_k{k}_2\"]=np.mean(globals()[f\"f3_arr_k{k}\"])\n",
    "            globals()[f\"c_k{k}_3\"]=np.mean(globals()[f\"f4_arr_k{k}\"])\n",
    "            \n",
    "#             print(\"c\", float(globals()[f\"c_k{k}_0\"]), \"type\")\n",
    "#             print(\"c\", float(globals()[f\"c_k{k}_1\"]), \"type\")\n",
    "#             print(\"c\", float(globals()[f\"c_k{k}_2\"]), \"type\")\n",
    "#             print(\"c\", float(globals()[f\"c_k{k}_3\"]), \"type\")\n",
    "            \n",
    "            ##computing each row of the new centroid/each cluster\n",
    "            c_row=[]\n",
    "            c_row.append(float(globals()[f\"c_k{k}_0\"]))\n",
    "            c_row.append(float(globals()[f\"c_k{k}_1\"]))\n",
    "            c_row.append(float(globals()[f\"c_k{k}_2\"]))\n",
    "            c_row.append(float(globals()[f\"c_k{k}_3\"]))\n",
    "            \n",
    "            ##print(\"c row\", c_row)\n",
    "            \n",
    "            ##adding each row to the new centroid matrix\n",
    "            new_c.append(c_row)\n",
    "            \n",
    "        \n",
    "        ##print(\"new c: \", new_c)\n",
    "        ##updating the new centroid\n",
    "        centroids=new_c\n",
    "        \n",
    "        if(iters>=1):\n",
    "            if(np.absolute(all_sse[iters] - all_sse[iters-1])/all_sse[iters-1] <= tol):\n",
    "                break\n",
    "                            \n",
    "\n",
    "    return assignments,centroids,all_sse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17685.47780000008, 3926.6652479654267, 2895.228347418268, 1951.4806189142712, 1354.325878364995, 1257.1546578796958, 1280.0577206377914, 1456.9465562836517, 938.6994771468194, 704.6408013506516]\n"
     ]
    }
   ],
   "source": [
    "all_msse_arr=[]\n",
    "new_data=remove_labels(data)\n",
    "##print(new_data)\n",
    "assignment_k1,centroids_k1,all_sse_k1=kmeans_clusteringv2(new_data,1,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k1)\n",
    "mean_sse_k1=np.mean(all_sse_k1)\n",
    "all_msse_arr.append(mean_sse_k1)\n",
    "\n",
    "assignment_k2,centroids_k2,all_sse_k2=kmeans_clusteringv2(new_data,2,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k2)\n",
    "mean_sse_k2=np.mean(all_sse_k2)\n",
    "all_msse_arr.append(mean_sse_k2)\n",
    "\n",
    "assignment_k3,centroids_k3,all_sse_k3=kmeans_clusteringv2(new_data,3,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k3)\n",
    "mean_sse_k3=np.mean(all_sse_k3)\n",
    "all_msse_arr.append(mean_sse_k3)\n",
    "\n",
    "assignment_k4,centroids_k4,all_sse_k4=kmeans_clusteringv2(new_data,4,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k4)\n",
    "mean_sse_k4=np.mean(all_sse_k4)\n",
    "all_msse_arr.append(mean_sse_k4)\n",
    "\n",
    "assignment_k5,centroids_k5,all_sse_k5=kmeans_clusteringv2(new_data,5,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k5)\n",
    "mean_sse_k5=np.mean(all_sse_k5)\n",
    "all_msse_arr.append(mean_sse_k5)\n",
    "\n",
    "assignment_k6,centroids_k6,all_sse_k6=kmeans_clusteringv2(new_data,6,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k6)\n",
    "mean_sse_k6=np.mean(all_sse_k6)\n",
    "all_msse_arr.append(mean_sse_k6)\n",
    "\n",
    "assignment_k7,centroids_k7,all_sse_k7=kmeans_clusteringv2(new_data,7,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k5)\n",
    "mean_sse_k7=np.mean(all_sse_k7)\n",
    "all_msse_arr.append(mean_sse_k7)\n",
    "\n",
    "assignment_k8,centroids_k8,all_sse_k8=kmeans_clusteringv2(new_data,8,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k8)\n",
    "mean_sse_k8=np.mean(all_sse_k8)\n",
    "all_msse_arr.append(mean_sse_k8)\n",
    "\n",
    "assignment_k9,centroids_k9,all_sse_k9=kmeans_clusteringv2(new_data,9,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k9)\n",
    "mean_sse_k9=np.mean(all_sse_k9)\n",
    "all_msse_arr.append(mean_sse_k9)\n",
    "\n",
    "assignment_k10,centroids_k10,all_sse_k10=kmeans_clusteringv2(new_data,10,50, pow(10,-3))\n",
    "# print(\"all sse array: \", all_sse_k10)\n",
    "mean_sse_k10=np.mean(all_sse_k10)\n",
    "all_msse_arr.append(mean_sse_k10)\n",
    "\n",
    "print(all_msse_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_=0\n",
    "avg_ = np.mean(all_msse_arr)\n",
    "#deviation_total = 0\n",
    "#computing standard deviation for each k 1,10\n",
    "stdev = [0 for x in range(10)]\n",
    "for i in range(10):\n",
    "    deviation_total = 0\n",
    "    deviation_total += (avg_ - all_msse_arr[i])**2\n",
    "    deviation = deviation_total/len(stdev) \n",
    "    stdev[i] = (deviation)**(1/2)\n",
    "##print(\"devvv\", stdev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,kplot = plt.subplots()\n",
    "\n",
    "all_k = [x for x in range(1,11)]\n",
    "##print(all_k)\n",
    "\n",
    "#plot of k vs avg accuracy\n",
    "kplot.scatter(all_k , all_msse_arr,color='r')\n",
    "\n",
    "#using plt.errorbar() method to show error-bar around the points that encode the standard deviation\n",
    "kplot.errorbar(all_k , all_msse_arr, yerr=stdev, color='b')\n",
    "#plot labels\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
